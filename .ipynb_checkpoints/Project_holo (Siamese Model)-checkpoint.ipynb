{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40ee8b2-cec4-4517-a223-f83a3020ff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HOLO graphs have been saved in the directory: sh\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "def load_and_process_data(prefix, folder):\n",
    "    node_file = f'{folder}/{prefix}_nodes.csv'\n",
    "    link_file = f'{folder}/{prefix}_links.csv'\n",
    "\n",
    "    node_data = pd.read_csv(node_file)\n",
    "    link_data = pd.read_csv(link_file)\n",
    "\n",
    "    # Assuming the ground truth labels are in the same format\n",
    "    labels = node_data['ground_truth'].values\n",
    "    features = node_data.drop(columns=['ground_truth'])\n",
    "\n",
    "    node_features = features[['atom_type', 'residue_type', 'radius', 'voromqa_sas_potential', 'residue_mean_sas_potential', 'residue_sum_sas_potential', 'residue_size', 'sas_area', 'voromqa_sas_energy', 'voromqa_depth', 'voromqa_score_a', 'voromqa_score_r', 'volume', 'volume_vdw', 'ufsr_a1', 'ufsr_a2', 'ufsr_c2', 'ufsr_c3', 'ev28', 'ev56']]\n",
    "    link_features = link_data[['atom_index1', 'atom_index2','area', 'boundary', 'distance', 'voromqa_energy', 'seq_sep_class', 'covalent_bond', 'hbond']]\n",
    "\n",
    "    edge_index = torch.tensor(np.array([link_features['atom_index1'].values, link_features['atom_index2'].values]), dtype=torch.long)\n",
    "\n",
    "    self_links = torch.arange(0, len(node_features))\n",
    "    edge_index = torch.cat([edge_index, torch.stack([self_links, self_links])], dim=1)\n",
    "    edge_index = torch.cat([edge_index, edge_index[[1, 0], :]], dim=1)  # Add reverse direction\n",
    "\n",
    "    node_features_tensor = torch.tensor(node_features.values, dtype=torch.float)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    data = Data(x=node_features_tensor, edge_index=edge_index, y=labels_tensor)\n",
    "\n",
    "    return data\n",
    "\n",
    "candidate_pairs_file = 'holo/candidate_pairs.txt'\n",
    "candidate_pairs = pd.read_csv(candidate_pairs_file, delim_whitespace=True)\n",
    "\n",
    "graphs = {}\n",
    "for index, row in candidate_pairs.iterrows():\n",
    "    holo_prefix = f\"{row['holo_pdb_id']}_{row['holo_chain_id']}\"\n",
    "    graphs[holo_prefix] = load_and_process_data(holo_prefix, 'holo')\n",
    "\n",
    "save_dir = 'sh'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for prefix, graph in graphs.items():\n",
    "    save_path = os.path.join(save_dir, f'{prefix}_graph.pt')\n",
    "    torch.save(graph, save_path)\n",
    "\n",
    "print(f\"All HOLO graphs have been saved in the directory: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeda619d-2c3c-40e4-8581-c0577581eef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [80449] to be smaller than self [32] apart from dimension 0 and to be smaller size than src [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 103\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     loss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 70\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m apo_batch, holo_batch \u001b[38;5;241m=\u001b[39m apo_batch\u001b[38;5;241m.\u001b[39mto(device), holo_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 70\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapo_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholo_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39msqueeze(), apo_batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     72\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mSiameseGVPModel.forward\u001b[0;34m(self, apo_data, holo_data)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, apo_data, holo_data):\n\u001b[0;32m---> 22\u001b[0m     apo_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapo_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     holo_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_structure(holo_data)\n\u001b[1;32m     24\u001b[0m     combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([apo_x, holo_x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mSiameseGVPModel.process_structure\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgvp1(x)\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgvp2(x)\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mgeom_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_mean_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/nn/pool/glob.py:61\u001b[0m, in \u001b[0;36mglobal_mean_pool\u001b[0;34m(x, batch, size)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mcount\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_ones\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected index [80449] to be smaller than self [32] apart from dimension 0 and to be smaller size than src [1]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as geom_nn\n",
    "import gvp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "class SiameseGVPModel(nn.Module):\n",
    "    def __init__(self, node_in_dims):\n",
    "        super(SiameseGVPModel, self).__init__()\n",
    "        self.gvp1 = gvp.GVP(node_in_dims, (64, 0), vector_gate=True, activations=(F.relu, None))\n",
    "        self.gvp2 = gvp.GVP((64, 0), (1, 0))\n",
    "        self.fc1 = nn.Linear(2, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, apo_data, holo_data):\n",
    "        apo_x = self.process_structure(apo_data)\n",
    "        holo_x = self.process_structure(holo_data)\n",
    "        combined = torch.cat([apo_x, holo_x], dim=1)\n",
    "        combined = F.relu(self.fc1(combined))\n",
    "        combined = self.fc2(combined)\n",
    "        return combined\n",
    "\n",
    "    def process_structure(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gvp1(x)\n",
    "        x = self.gvp2(x)\n",
    "        print(f\"x[0].shape: {x[0].shape}, data.batch.shape: {data.batch.shape}\")\n",
    "        x = geom_nn.global_mean_pool(x[0], data.batch)\n",
    "        return x\n",
    "\n",
    "class ProteinPairsDataset(Dataset):\n",
    "    def __init__(self, data_pairs):\n",
    "        self.data_pairs = data_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_pairs[idx]\n",
    "\n",
    "def load_data_pairs(apo_folder='sg', holo_folder='sh', pairs_file='apo/candidate_pairs.txt'):\n",
    "    pairs = pd.read_csv(pairs_file, delim_whitespace=True)\n",
    "    data_pairs = []\n",
    "\n",
    "    for index, row in pairs.iterrows():\n",
    "        apo_prefix = f\"{row['apo_pdb_id']}_{row['apo_chain_id']}\"\n",
    "        holo_prefix = f\"{row['holo_pdb_id']}_{row['holo_chain_id']}\"\n",
    "\n",
    "        apo_graph_path = os.path.join(apo_folder, f'{apo_prefix}_graph.pt')\n",
    "        holo_graph_path = os.path.join(holo_folder, f'{holo_prefix}_graph.pt')\n",
    "\n",
    "        if os.path.exists(apo_graph_path) and os.path.exists(holo_graph_path):\n",
    "            apo_graph = torch.load(apo_graph_path)\n",
    "            holo_graph = torch.load(holo_graph_path)\n",
    "            data_pairs.append((apo_graph, holo_graph))\n",
    "\n",
    "    return data_pairs\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for apo_batch, holo_batch in loader:\n",
    "        apo_batch, holo_batch = apo_batch.to(device), holo_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(apo_batch, holo_batch)\n",
    "        loss = criterion(output.squeeze(), apo_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "\n",
    "def collate_data_pairs(batch):\n",
    "    apo_data_list, holo_data_list = zip(*batch)\n",
    "    apo_batch = Batch.from_data_list(apo_data_list)\n",
    "    holo_batch = Batch.from_data_list(holo_data_list)\n",
    "    return apo_batch, holo_batch\n",
    "\n",
    "# Load data pairs\n",
    "data_pairs = load_data_pairs()\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = ProteinPairsDataset(data_pairs)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_data_pairs)\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SiameseGVPModel(node_in_dims=(20, 0)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    loss_history.append(loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.plot(loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e18f8e-e279-4c7f-abab-d47350f2123f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
